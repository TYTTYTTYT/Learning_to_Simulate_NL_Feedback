# Training a User Feedback Simulator

### Set up the virtual environment

1. Follow all instructions on the [project homepage](https://github.com/hyan5/Learning_to_Simulate_NL_Feedback/tree/main) to set up the python virtual environment and install all dependencies.

2. Download all necessary datasets and put them into the "$ISP_HOME/data" folder.

3. Generate the template feedback for SPLASH data and remove structural errors.

4. If reproduce our experiments, you should download Collected error prases on EditSQL and repeat the previous step to remove structural errors in EditSQL:
```
cd $ISP_HOME/utils
python generate_template_feedback.py -i ../data/editsql/train.json -o ../data/editsql/train_w_template_feedback.json --no_underscore --no_quote --connect_foreign_key_group --use_modified_schema
python generate_template_feedback.py -i ../data/editsql/dev.json -o ../data/editsql/dev_w_template_feedback.json --no_underscore --no_quote --connect_foreign_key_group --use_modified_schema
python generate_template_feedback.py -i ../data/editsql/test.json -o ../data/editsql/test_w_template_feedback.json --no_underscore --no_quote --connect_foreign_key_group --use_modified_schema
```
### Data Preprocessing
1. Put the evaluation checkpoint under folder "eval_ckp"
```
cd $ISP_HOME/feedback_simulation
python preprocess.py --sep --strip --use_modified_schema --train [train data path] --dev [dev data path] --test [test data path] --target feedback --format tqes --out_dir [out dir]

arguments:
--sep			whether use the special tokens to separate the different parts
--strip		remove all white space at the end
--use_modified_schema		use the canonical name of database schema
--train  	the path of train file, e.g. "../data/splash/train_20_80.json"
--dev			the path of dev file, e.g. "../data/splash/dev_w_template_feedback.json"
--test		the path of test file, e.g. "../data/splash/test_w_template_feedback.json"
--target	the target output. use "edits" for error correction model
--format	the order to concatenate the inputs. (Use "tqes" to reproduce our experiments)
--out_dir where to store the processed data. 
```

### Running train.py
```
python train.py --data_dir [root folder of all processed data] --data_revision [name of processed data folder] --model t5-large --evaluation_ckp [evaluator path]

arguments:
	--data_dir	# the root folder of all processed data
	--data_revision	# the name of processed data folder
	--model 	# the model type [t5-base, t5-large]
	--evaluation_ckp #feedback evaluation model path
```
### Running prediction.py
If you have checkpoints and want to only load the checkpint and run prediction:
```
python prediction.py --data_dir [root folder of all processed data] --data_revision [name of processed data folder] --model t5-large --ckp [path of checkpoint] --evaluation_ckp [evaluator path]

arguments:
	--data_dir	# the root folder of all processed data
	--data_revision	# the name of processed data folder
	--model 	# the model type [t5-base, t5-large]
	--ckp #the path of saved checkpoint
	--evaluation_ckp #feedback evaluation model path
```

5. Combine the simulated feedback into the EditSQL dataset

```
# Put the "test.sim" and "dev.sim" files generated by the feedback simulator from previous step into the folder "$ISP_HOME/data/editsql"
# Run the combine_feedback.py
# It will generate two files "train_w_simulated_feedback.json" and "dev_w_simulated_feedback.json"

cd $ISP_HOME/data
python combine_feedback.py --file_path=editsql/train_w_template_feedback.json --sim_file=editsql/test.sim --out_dir=editsql/train_w_simulated_feedback.json
python combine_feedback.py --file_path=editsql/dev_w_template_feedback.json --sim_file=editsql/dev.sim --out_dir=editsql/dev_w_simulated_feedback.json

arguments:
	--file_path 	the path of the data
	--sim_file 	the path of the simulated feedback
	--out_dit 	the path of the output file
```