# Experiments Instruction

### Set up the virtual environment

1. Follow all instructions on the [project homepage](main) to set up the python virtual environment and install all dependencies.

2. Download all necessary datasets and put them into the "$ISP_HOME/data" folder.

3. Generate the template feedback for SPLASH data and remove structural errors

### Experiment Setting 1 train an error correction model using SPLASH + feedback of EditSQL simulated by our feedback generator

1. The error parse collected from EditSQL on Spider's train set is provided under "$ISP_HOME/data/editsql" folder
2. Run the following commands to generate the template feedback for EditSQL

```
cd $ISP_HOME/utils
python generate_template_feedback.py -i ../data/editsql/train.json -o ../data/editsql/train_w_template_feedback.json --no_underscore --no_quote --connect_foreign_key_group
python generate_template_feedback.py -i ../data/editsql/dev.json -o ../data/editsql/dev_w_template_feedback.json --no_underscore --no_quote --connect_foreign_key_group
python generate_template_feedback.py -i ../data/editsql/test.json -o ../data/editsql/test_w_template_feedback.json --no_underscore --no_quote --connect_foreign_key_group
```

3. Prepare the data for feedback simulation on EditSQL

```
cd $ISP_HOME/feedback_simulation
python preprocess.py --sep --strip --use_modified_schema --train=../data/editsql/train_w_template_feedback.json --dev=../data/edisql/dev_w_template_feedback.json --test=../data/editsql/test_w_template_feedback.json --target=gold_parse --format=tqes --out_dir=data/editsql_tqes_feedback

arguments:
--sep			whether use the special tokens to separate the different parts
--strip		remove all white space at the end
--use_modified_schema		use the canonical name of database schema
--train  	the path of train file, should like "../data/splash/train_20_80.json"
--dev			the path of dev file, should be "../data/splash/dev_w_template_feedback.json"
--test		the path of test file, should be "../data/splash/test_w_template_feedback.json"
--target	the target output. use "edits" for error correction model
--format	the order to concatenate the inputs. We should use "feqs" in the correction model
--out_dir where to store the processed data. 

Notice:
a) The best setting for feedback simulation is in the form of "TQES: Template feedback + Question + Explanation + Database Schema" so far. Therefore, I prepare the data in the same form "TQES"
b) The processed data is saved in the "$ISP_HOME/feedback_simulation/data/editsql_tqes_feedback"
```

4. Running feedback generation model to simulate feedback on EditSQL.

```
cd $ISP_HOME/feedback_simulation/feedback_generation
python prediction.py --data_dir=../data --data_revision=editsql_tqes_feedback --model=t5-large --ckp=results-t5-large-editsql_tqes_feedback/checkpoint-384

arguments:
	--data_dir	# the path of data folder
	--data_revision	# the path of processed data folder
	--model 	# the model type [t5-base, t5-large]
	--ckp	# the path of the best checkpoint of the feedback generation model
	
Notice:
	a) I have trained this generation model. I will upload it to the github
	b) The simulated feedback will be saved in the "results-t5-large-editsql_tqes_feedback" folder
	c) The simulated files are "train.sim", "dev.sim", "test.sim"
```

5. Combine the simulated feedback into the EditSQL dataset

```
# Put the "test.sim" and "dev.sim" files generated by the feedback simulator from previous step into the folder "$ISP_HOME/data/editsql"
# Run the combine_feedback.py
# It will generate two files "train_w_simulated_feedback.json" and "dev_w_simulated_feedback.json"

cd $ISP_HOME/data
python combine_feedback.py --file_path=editsql/train_w_template_feedback.json --sim_file=editsql/test.sim --out_dir=editsql/train_w_simulated_feedback.json
python combine_feedback.py --file_path=editsql/dev_w_template_feedback.json --sim_file=editsql/dev.sim --out_dir=editsql/dev_w_simulated_feedback.json

arguments:
	--file_path 	the path of the data
	--sim_file 	the path of the simulated feedback
	--out_dit 	the path of the output file
```

6. Combine the SPLASH and EditSQL as one dataset

```
# Run combine_two_datasets.py to combine the two datasets
python combine_two_datasets.py --file_one=splash/train_w_template_feedback.json --file_two=editsql/train_w_simulated_feedback.json --file_one_feedback=feedback --file_two_feedback=feedback --out_dir=splash/splash_w_feedback_editsql_w_simulated_feedback.json

arguments:
	--file_one 		the path of the first dataset
	--file_two 		the path of the second dataset
	--file_one_feedback 	the feedback used in the first dataset. [feedback, template_feedback]
	--file_two_feedback 	the feedback used in the first dataset. [feedback, template_feedback]
```

7. Prepare the data to train the error correction model.

```
python preprocess.py --sep --strip --use_modified_schema --train=../data/splash/splash_w_feedback_editsql_w_simulated_feedback.json --dev=../data/splash/dev_w_template_feedback.json --test=../data/splash/test_w_template_feedback.json --target=edits --format=feqs --out_dir=data/splash_feedback_editsql_simulated_feedback_feqs_edits
```

8. Training the error correction model

```
cd $ISP_HOME/feedback_simulation/Correction_Model
python train_edit.py --data_dir=../data --data_revision=splash_feedback_editsql_simulated_feedback_feqs_edits --model=t5-base
```

### Experiment Setting 2 train an error correction model using SPLASH + feedback of EditSQL simulated by template feedback

1. If you follow the experiment 1 instruction, the data of editsql has been processed correctly. Otherwise, please follow the step 1 ~ step 5 from experiment 1.
2. Combine the SPLASH and EditSQL as one dataset

```
# Run combine_two_datasets.py to combine the two datasets
python combine_two_datasets.py --file_one=splash/train_w_template_feedback.json --file_two=editsql/train_w_simulated_feedback.json --file_one_feedback=feedback --file_two_feedback=template_feedback --out_dir=splash/splash_w_feedback_editsql_w_template_feedback.json

arguments:
	--file_one 		the path of the first dataset
	--file_two 		the path of the second dataset
	--file_one_feedback 	the feedback used in the first dataset. [feedback, template_feedback]
	--file_two_feedback 	the feedback used in the first dataset. [feedback, template_feedback]
```

3. Prepare the data to train the error correction model.

```
python preprocess.py --sep --strip --use_modified_schema --train=../data/splash/splash_w_feedback_editsql_w_template_feedback.json --dev=../data/splash/dev_w_template_feedback.json --test=../data/splash/test_w_template_feedback.json --target=edits --format=feqs --out_dir=data/splash_feedback_editsql_template_feedback_feqs_edits
```

4. Training the error correction model

```
cd $ISP_HOME/feedback_simulation/Correction_Model
python train_edit.py --data_dir=../data --data_revision=splash_feedback_editsql_template_feedback_feqs_edits --model=t5-base
```

### Train an error correction model using K% of SPLASH + feedback on the remaining (100-K)% simulated by our feedback generator

1. Move to the splash data folder and run the "train_split.py", and use option "--percent" to decide how much real user feedback is needed in the training data.

```
cd $ISP_HOME/data/splash
python train_split.py --percent=10 

argument:
	--percent  how much data is needed with the real human feedback
	
Notice:
	the script will generate the two json files. (e.g. --percent=10, train_10.json and train_90.json)
```

2. Train Evaluation Model

   2.1 Open "train_spider_aligner.py" under the "$ISP_HOME/feedback_evaluation" folder and manually replace the training file path at line 458:

   ```
   train_data_file = '../data/splash/train_10.json'
   ```

   2.2 Train the evaluation model:

   ```
   python train_spider_aligner.py
   
   # Before you train the feedback evaluation model, please manually cleaning the cache folder if the traing data is not the same. Otherwise, it will use cached data during training.
   # All parameters has been set to the best found in past experiments
   ```

   2.3 You can run this script on Hopper as well. A template slurm file is attached in the folder. 

   2.4 You have to modify the "wandb" settings to make the script correctly reports to the "w&b"

3. Train Feedback generation model

   3.1 Prepare the data

   ```
   cd $ISP_HOME/feedback_simulation
   python preprocess.py --sep --strip --use_modified_schema --train=../data/splash/train_10.json --dev=../data/splash/dev_w_template_feedback.json --test=../data/splash/train_90.json --target=feedback --format=tqes --out_dir=data/splash_tqes_feedback
   
   Notice:
   	a) We are mainly focus on three settings. You can modify the "--format" and "--out_dir" option to generate different combinations of input (cwqes, dqes, tqes)
   	b) The training file for the low data experiment should be the same as the one used in training the evaluation model
   	c) The test file here is the remaining 95%/90%/80% SPLASH train data
   	d) The "--target" should be "feedback" for feedback generation model
   ```

   3.2 Put the best evaluation checkpoint into the "feedback_genertion/eval_ckp" folder and modify the name of the evaluation model to "evaluation.pt"

   3.3 Train the feedback generator

   ```
   cd $ISP_HOME/feedback_simulation/feedback_generation
   python train.py --data_dir=../data --data_revision=splash_tqes_feedback --model=t5-large
   
   arguments:
   	--data_dir		the path of the data folder.
   	--data_revision 	the folder of the preprocessed data
   	--model			the model used [t5-base, t5-large]
   	
   For different settings, you can use different folder name to store the preprocessed data.
   ```

   3.4 You can run this script on Hopper as well. A tamplate slurm file is attached in the folder. 

   3.5 You have to modify the "wandb" settings to make the script correctly reports to the "w&b"

   3.6 If you want to run this parallel with the feedback evaluation model. You can use the best checkpoint trained with full splash data. I will upload it to GitHub. After we complete the training process for both models. We can select the best checkpoint based on the trained evaluation model.

4. Train the error correction model

   4.1Simulate feedback on the remaining 95%/90%/80% SPLASH train set. The output file will be saved as the name "test.sim"

   ```
   # In step 3, we alredy include the reamining train data as test file in the training of feedback generator
   # We can simulate the feedback based on the best checkpoint
   python prediction.py --data_dir=../data --data_revision=splash_tqes_feedback --model=t5-large --ckp=[the path of the best checkpoint]
   
   arguments:
   	--data_dir		the path of the data folder.
   	--data_revision 	the folder of the preprocessed data
   	--model			the model used for fine-tuning [t5-base, t5-large]
   	--ckp    		the path of the best checkpoint
   ```

   4.2 Combining the simulated feedback into the "train_90.json" file:

   ```
   #Put all train_10.json, train_90.json, and simulated feedback result "test.sim" into the folder "$ISP_HOME/data/splash"
   
   cd $ISP_HOME/data
   python combine_feedback.py --file_path=splash/train_90.json --sim_feedback=splash/test.sim --out_dir=splash/train_90_w_simulated_feedback.json
   ```

   4.3 Combining the train data

   ```
   python combine_two_datasets.py --file_one=splash/train_10.json --file_two=splash/train_90_w_simulated_feedback.json --file_one_feedback=feedback --file_two_feedback=feedback --out_dir=splash/train_10_feedback_90_w_simulated_feedback.json
   
   arguments:
   	--file_one 		the path of the first dataset
   	--file_two 		the path of the second dataset
   	--file_one_feedback 	the feedback used in the first dataset. [feedback, template_feedback]
   	--file_two_feedback 	the feedback used in the first dataset. [feedback, template_feedback]
   ```

   4.4 Prepare the data to train the error correction model

   ```
   cd $ISP_HOME/feedback_simulation
   python preprocess.py --sep --strip --use_modified_schema --train=../data/splash/train_10_feedback_90_w_simulated_feedback.json --dev=../data/splash/dev_w_template_feedback.json --test=../data/splash/test_w_template_feedback.json --target=edits --format=feqs --out_dir=data/splash_10_feedback_90_simulated_feedback
   
   Notice:
   	The "--target" should be "edits" for error correction model
   ```

   4.5 Train the error correction model

   ```
   cd $ISP_HOME/feedback_simulation/Correction_Model
   python train_edit.py --data_dir=../data --data_revision=splash_10_feedback_90_simulated_feedback --model=t5-base
   ```

   4.6 You can run the job on Hopper. One template slurm script is included in the folder

   4.7 You have to modify the wandb settings in the code if you want to report to 'wandb'

### Train an error correction model using K% of SPLASH + feedback on the remaining (100-K)% simulated by template feedback

1. Move to the splash data folder and run the "train_split.py", and use option "--percent" to decide how much real user feedback is needed in the training data.

```
cd $ISP_HOME/data/splash
python train_split.py --percent=10 

argument:
	--percent  how much data is needed with the real human feedback
	
Notice:
	the script will generate the two json files. (e.g. --percent=10, train_10.json and train_90.json)
```

2. Combine the two splits as one training set

```
python combine_two_datasets.py --file_one=splash/train_10.json --file_two=splash/train_90.json --file_one_feedback=feedback --file_two_feedback=template_feedback --out_dir=splash/train_10_feedback_90_w_template_feedback.json

arguments:
	--file_one 		the path of the first dataset
	--file_two 		the path of the second dataset
	--file_one_feedback 	the feedback used in the first dataset. [feedback, template_feedback]
	--file_two_feedback 	the feedback used in the first dataset. [feedback, template_feedback]
```

3. Prepare the data to train the error correction model

```
cd $ISP_HOME/feedback_simulation
python preprocess.py --sep --strip --use_modified_schema --train=../data/splash/train_10_feedback_90_w_template_feedback.json --dev=../data/splash/dev_w_template_feedback.json --test=../data/splash/test_w_template_feedback.json --target=edits --format=feqs --out_dir=data/splash_10_feedback_90_template_feedback

Notice:
	The "--target" should be "edits" for error correction model
```

4. Train the error correction model

```
cd $ISP_HOME/feedback_simulation/Correction_Model
python train_edit.py --data_dir=../data --data_revision=splash_10_feedback_90_template_feedback --model=t5-base
```

