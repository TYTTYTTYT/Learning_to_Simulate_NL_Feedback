{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates\n",
    "The feedback generation templates and the reimplementation explanation templates from the NL-Edit paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrections since last meeting:\n",
    "1. Minor errors are fixed.\n",
    "2. Using foreign key relationship to judge whether two column names are equal. If on column is another's foreign key, the are equaivelent. Otherwise they are not even they have identical column name. Foreign keys are defined as a subgraph of all connected columns.\n",
    "3. Connect conditions in `WHERE` clause according to the correct logical operations, `AND` or `OR` accordingly.\n",
    "   1. *cond<sub>1</sub> (and | or) cond<sub>2</sub> ...*\n",
    "   2. *you should consider (both | either) of the conditions rather than (either | both) of them.*\n",
    "4. When adding additional table, also mention the old table. \n",
    "   * *additionally use the information from the tab_name<sub>add</sub> table besides the tab_name<sub>old</sub>.*\n",
    "5. Applied three types of tags to category different tokens in feedback templates.\n",
    "   1. `add` represents added **column names**, **table names**, and **order directions** or **largest smallest**.\n",
    "   2. `sub` represents removed **column names**, **table names**, and **order directions** or **largest smallest**.\n",
    "   3. `info` represents other information which is necessary to correct the wrong query.\n",
    "6. The sequence correction of each part depends on the sequence of SQL execution.\n",
    "7. If in the correct parse `JOIN ON` condition, two columns are equal, their foreign key group will be unioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations\n",
    "1. When mention column names, literal ambituity only depends on whether there are identical column names in other tables which also used in the current SQL query. In feedback generation, we should consider all tables mentioned in the wrong and correct queries.\n",
    "2. When judge the equivalence between column names, if the two columns are from different tables, only when they are foreign keys of the each other, they are considered as the same column.\n",
    "3. When add an extra table to the wrong query, users tend to mentioned the existing table in wrong table.\n",
    "4. The input of BART-rephrasing mode should take both question and template feedback as input. Because sometimes users are rephrase the questions.\n",
    "5. There are some column name **abbreviations** in the SPIDER dataset, like `student id` for `stuid` and `longitude` for `long`. Sometimes users use explanations and sometimes they use the original names.\n",
    "6. There are 618 cases in 9314 samples of adding or removing an entire SQL sub-query of UNION/INTERSECT/EXCEPT. 3 cases of adding SQL sub-query in FROM clause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- [ ] Correct the **remove the entire GROUPBY clause** tempalte follows the overleaf file.\n",
    "- [ ] Check the importance of each clause, 10 samples for each case:\n",
    "  - [ ] SELECT vs FROM\n",
    "  - [ ] SELECT vs WHERE\n",
    "  - [ ] SELECT vs GROUP BY\n",
    "  - [ ] SELECT vs ORDER BY\n",
    "  - [ ] FROM vs WHERE\n",
    "  - [ ] FROM vs GROUP BY\n",
    "  - [ ] FROM vs ORDER BY\n",
    "  - [ ] WHERE vs GROUP BY\n",
    "  - [ ] WHERE vs ORDER BY\n",
    "  - [ ] GROUP BY vs ORDER BY\n",
    "- [x] Implement the `primary` and `secondary` tags.\n",
    "- [ ] Test the Explanation on the entire SPIDER dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test NLTK tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "sent = 'in step 1, find for each value of MANAGER_ID and DEPARTMENT_ID whose number of EMPLOYEE_ID greater than or equals 4 . in step 2, make sure no repetition in the results.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in step 1, find for each value of MANAGER_ID and DEPARTMENT_ID whose number of EMPLOYEE_ID greater than or equals 4 .', 'in step 2, make sure no repetition in the results.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate samples of modifying / adding / removing the GROUP_BY Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import  Path\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "sys.path.append(os.path.dirname(Path(SCRIPT_DIR).parent))\n",
    "\n",
    "from utils.utils import load_json, edit_size, store_json\n",
    "from tqdm import tqdm\n",
    "from sqlComponents import Query\n",
    "import json\n",
    "import config\n",
    "from templates import explanation, feedback, find_span\n",
    "from utils.utils import print_dict\n",
    "from config import ADD_TAG1, ADD_TAG2, SUB_TAG1, SUB_TAG2\n",
    "data = load_json('/Users/taiyintao/Interactive_Semantic_Parsing_Correction/splash_structure_error_removed/train.json')\n",
    "data += load_json('/Users/taiyintao/Interactive_Semantic_Parsing_Correction/splash_structure_error_removed/dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8536/8536 [05:45<00:00, 24.67it/s]\n"
     ]
    }
   ],
   "source": [
    "add_groupby = []\n",
    "remove_groupby = []\n",
    "change_or_remove_groupby_column = []\n",
    "add_groupby_column = []\n",
    "\n",
    "for id, sample in tqdm(list(enumerate(data))):\n",
    "    sample.pop('beam')\n",
    "    db_id = sample['db_id']\n",
    "    gold_sql = sample['gold_parse']\n",
    "    pred_sql = sample['predicted_parse_with_values']\n",
    "    original_explaination = sample['predicted_parse_explanation']\n",
    "    \n",
    "    pred_query = Query(pred_sql, db_id)\n",
    "    gold_query = Query(gold_sql, db_id)\n",
    "    size = edit_size(pred_sql, gold_sql, db_id)\n",
    "    sample['edit_size'] = size\n",
    "    fb = feedback(pred_sql, gold_sql, db_id)\n",
    "    sample['generated_feedback'] = fb\n",
    "\n",
    "    original_show_tag = config.SHOW_TAG\n",
    "    config.SHOW_TAG = True\n",
    "    fd = feedback(pred_sql, gold_sql, db_id)\n",
    "    primary_span = find_span(ADD_TAG1, ADD_TAG2, [SUB_TAG1, SUB_TAG2], fd)\n",
    "    secondary_span = find_span(SUB_TAG1, SUB_TAG2, [ADD_TAG1, ADD_TAG2], fd)\n",
    "    config.SHOW_TAG = original_show_tag\n",
    "\n",
    "    sample['primary_span'] = primary_span\n",
    "    sample['secondary_span'] = secondary_span\n",
    "\n",
    "    if not gold_query.group_by.is_empty and pred_query.group_by.is_empty:           # add group by\n",
    "        add_groupby += [sample]\n",
    "    if gold_query.group_by.is_empty and not pred_query.group_by.is_empty:           # remove group by\n",
    "        remove_groupby += [sample]\n",
    "    if not gold_query.group_by.is_empty and not pred_query.group_by.is_empty:       # modifying the groupby\n",
    "        if gold_query.group_by != pred_query.group_by:\n",
    "            gold_groupby = set(gold_query.group_by.args)\n",
    "            pred_groupby = set(pred_query.group_by.args)\n",
    "\n",
    "            added = list(gold_groupby - pred_groupby)\n",
    "            removed = list(pred_groupby - gold_groupby)\n",
    "\n",
    "            if len(removed) == 0 and len(added) > 0:                                # add column(s) in groupby\n",
    "                add_groupby_column += [sample]\n",
    "            else:\n",
    "                change_or_remove_groupby_column += [sample]                         # change or remove column(s) in groupby\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = add_groupby_column\n",
    "average = sum(list(map(lambda x: x['edit_size'], current))) / len(current)\n",
    "print(f\"{len(current)} cases in {len(data)} samples, average Edit Size: {average}\")\n",
    "print_dict(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b0239994b6dc92b3206fbde7a2c58c21079738e9a586b8700fc5ffe77b90915"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('text2sql': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
